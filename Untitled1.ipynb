{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: /Users/andrewnorris/Library/Jupyter/runtime/kernel-f3ae187d-301a-417d-86c6-ec2a43ef6fc0 (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute '/Users/andrewnorris/Library/Jupyter/runtime/kernel-f3ae187d-301a-417d-86c6-ec2a43ef6fc0'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewnorris/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import unittest\n",
    "\n",
    "\n",
    "def url_validator (url):\n",
    "    \"\"\"validate the format of a URL\"\"\"\n",
    "    try:\n",
    "        result = urlparse(url)\n",
    "        return all([result.scheme, result.netloc, result.path])\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "class TestVerifyDatasets (unittest.TestCase):\n",
    "    ALLOWED_FIELDS = set([\n",
    "            \"alt_ids\",\n",
    "            \"alt_title\",\n",
    "            \"date\",\n",
    "            \"description\",\n",
    "            \"doi\",\n",
    "            \"id\",\n",
    "            \"provider\",\n",
    "            \"title\",\n",
    "            \"url\",\n",
    "            \"original\"\n",
    "            ])\n",
    "\n",
    "    PAT_ID_FORMAT = re.compile(r\"^dataset\\-(\\d+)$\")\n",
    "\n",
    "    PAT_LEADING_SPACE = re.compile(r\"^\\s.*\")\n",
    "    PAT_TRAILING_SPACE = re.compile(r\".*\\s$\")\n",
    "\n",
    "\n",
    "    def setUp (self):\n",
    "        \"\"\"load the dataset list\"\"\"\n",
    "        self.datasets = []\n",
    "        filename = \"datasets.json\"\n",
    "        #filename = \"test.json\"\n",
    "\n",
    "        with open(filename, \"r\") as f:\n",
    "            self.datasets = json.load(f)\n",
    "\n",
    "\n",
    "    def test_file_loaded (self):\n",
    "        print(\"\\n{} datasets loaded\".format(len(self.datasets)))\n",
    "        self.assertTrue(len(self.datasets) > 0)\n",
    "\n",
    "\n",
    "    def test_has_required_fields (self):\n",
    "        for dataset in self.datasets:\n",
    "            if not set([\"id\", \"title\", \"provider\"]).issubset(dataset.keys()):\n",
    "                raise Exception(\"{}: missing required fields\".format(dataset[\"id\"]))\n",
    "\n",
    "\n",
    "    def test_has_valid_url (self):\n",
    "        for dataset in self.datasets:\n",
    "            if \"url\" in dataset:\n",
    "                url = dataset[\"url\"]\n",
    "\n",
    "                if url == \"\" or not url:\n",
    "                    pass\n",
    "                elif not url_validator(url):\n",
    "                    raise Exception(\"{}: badly formed URL {}\".format(dataset[\"id\"], url))\n",
    "\n",
    "\n",
    "    def test_each_field (self):\n",
    "        for dataset in self.datasets:\n",
    "            for key in dataset.keys():\n",
    "                if key not in self.ALLOWED_FIELDS:\n",
    "                    raise Exception(\"{}: unknown field name {}\".format(dataset[\"id\"], key))\n",
    "\n",
    "\n",
    "    def test_unique_titles (self):\n",
    "        title_set = set([])\n",
    "\n",
    "        for dataset in self.datasets:\n",
    "            title = dataset[\"title\"]\n",
    "\n",
    "            if title in title_set:\n",
    "                raise Exception(\"{}: duplicate title {}\".format(dataset[\"id\"], title))\n",
    "            else:\n",
    "                title_set.add(title)\n",
    "\n",
    "\n",
    "    def test_id_sequence (self):\n",
    "        id_list = []\n",
    "\n",
    "        for dataset in self.datasets:\n",
    "            m = self.PAT_ID_FORMAT.match(dataset[\"id\"])\n",
    "\n",
    "            if not m:\n",
    "                raise Exception(\"badly formed ID |{}|\".format(dataset[\"id\"]))\n",
    "            else:\n",
    "                id = int(m.group(1))\n",
    "\n",
    "                if id in id_list:\n",
    "                    raise Exception(\"duplicate ID |{}|\".format(dataset[\"id\"]))\n",
    "                else:\n",
    "                    id_list.append(id)\n",
    "\n",
    "\n",
    "    def test_enum_providers (self):\n",
    "        provider_set = set([])\n",
    "\n",
    "        for dataset in self.datasets:\n",
    "            provider_set.add(dataset[\"provider\"])\n",
    "\n",
    "        self.assertTrue(len(provider_set) > 0)\n",
    "        print(\"\\n providers:\")\n",
    "\n",
    "        for provider in sorted(list(provider_set)):\n",
    "            print(provider)\n",
    "\n",
    "\n",
    "    def has_clean_name (self, dataset, field):\n",
    "        val = dataset[field]\n",
    "\n",
    "        if self.PAT_LEADING_SPACE.match(val):\n",
    "            raise Exception(\"{}: leading space in {} |{}|\".format(dataset[\"id\"], field, val))\n",
    "        elif self.PAT_TRAILING_SPACE.match(val):\n",
    "            raise Exception(\"{}: trailing space in {} |{}|\".format(dataset[\"id\"], field, val))\n",
    "\n",
    "\n",
    "    def test_clean_names (self):\n",
    "        for dataset in self.datasets:\n",
    "            self.has_clean_name(dataset, \"title\")\n",
    "            self.has_clean_name(dataset, \"provider\")\n",
    "    \n",
    "    def test_related_datasets (self):\n",
    "        # if a dataset has an 'original' subdict that includes a `joins_to` field, check that the\n",
    "        # dataset exists in datasets.json\n",
    "        for dataset in self.datasets:\n",
    "            if 'original' in dataset.keys():\n",
    "                if 'joins_to' in dataset['original'].keys():\n",
    "                    for ds in dataset['original']['joins_to']:\n",
    "                        if ds not in list(set([f['id'] for f in self.datasets])):\n",
    "                            raise Exception(\"Metadata for {} indicates that the dataset can be joined to {}, but {} is not in datasets.json. Please update datasets.json or fix the metadata field joins_to\".format(dataset['id'], ds,ds))\n",
    "                \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
